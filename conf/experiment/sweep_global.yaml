# @package _global_

defaults:
  - sweep_base
  - override /datamodule: global
  - override /model: global
  - override /model/net: global
  - override /model/net@model.head: regressor
  - override /metric: val_loss

# name of the run determines folder name in logs
name: "geodesic_regressor"

epochs: 1000

# Model parameters
model:
  log_figure_every_n_epoch: 50
  net:
    emb_dim: ${local_emb_dim}           # Embedding dimension of local metric
  head:
    emb_dim: ${local_emb_dim}           # Embedding dimension of local metric
    add_norm: false

# Datamodule
datamodule:
  k: 2
  panorama: true
  per_env_batches: false
  val_batch_size: 512

# Sweeper tweaks
hydra:
  sweeper:
    direction: minimize
    params:
      # Network
      model.noise: choice(0, 1e-3, 1e-2, 1e-1)
      model.net.n_layers: choice(2, 4, 6)
      model.net.activation: choice(relu, leaky_relu)
      model.net.p_dropout: choice(0.0)
      model.net.normalize_input: choice(true)
      # Head
      model.head.aggregation: choice(concat, relative)
      model.head.out_activation: choice(elu)
      # Optimizer
      model.optimizer.lr: tag(log, interval(1e-4, 1e-3))
      model/optimizer: choice(adam, adamw)
      model/lr_scheduler_config: choice(no_scheduler)
      # Datamodule
      datamodule.batch_size: choice(256, 512)
      datamodule.augmentations: choice(false, augmented)